function [p2_theta_ML,p2_theta_MAP] = HS2018_SysID_final_p2_15819790(p2_u,p2_y)
close all
clc
%% --------------------------------------------------------------------- %%
%% System Identification Midterm Problem 2
%% --------------------------------------------------------------------- %%

%% My details
disp(' ');
disp('    ###########################################################')
disp('    #          SYSTEM IDENTIFICATION FINAL PROBLEM 2          #')
disp('    #              Student Name: Charlotte Moraldo            #')
disp('    #                Legi Number: 15-819-790                  #')
disp('    ###########################################################')
disp(' ');

% Plot booleans
PLOT1 = false;
PLOT2_y = true;
PLOT3_y = true;

% Plot input and output preliminarily
if PLOT1
    figure(20)
    plot(p2_u); hold on; grid on;
    plot(p2_y);
end

% Initialization parameters
N = length(p2_u);
c1 = 0.043;
c2 = -0.05;
mu = 0;
lambda = 1;

% Noise
v = randn(N,1);

%% --------------------------------------------------------------------- %%
%% PART 1 
%% --------------------------------------------------------------------- %%
disp(' ');
disp('#####################################################################')
disp('#                             PART 1:                               #')
disp('#                    Maximum Likelihood Method                      #')
disp('#####################################################################')
disp(' ');

%% Compute statistics of the error
% mean
nu = zeros(N,1);

% covariance
for k = 1:N
    for l = 1:N
        if k == 1 && l == 1
            sigma(k,l) = (c1^2)*lambda;
        elseif k == l && k >= 2
            sigma(k,l) = (c1^2+c2^2)*lambda;
        elseif (k == 1 && l == 2) || (k == 2 && l == 1)
            sigma(k,l) = c1*c2*lambda;
        elseif abs(k-l) == 1 && min(k,l) >= 2
            sigma(k,l) = c1*c2*lambda;  
        elseif abs(k-l) >= 2
            sigma(k,l) = 0;
        else
            disp('Error')
        end
    end
end

% rough estimate of theta
thetaML = 0;

% form the error vector: Z(k) = y(k) - u(k) - theta*u(k-1)
z = zeros(N,1);
z(1) = p2_y(1) - p2_u(1);
z(2) = p2_y(2) - p2_u(2) - thetaML*p2_u(1);
for k=3:N
    z(k) = p2_y(k) - p2_u(k) - thetaML*p2_u(k-1);
end


%% Optimization
u = zeros(N,2);
u(:,1) = p2_u(:);
u(2:end,2) = p2_u(1:end-1);
disp('-----------------------------fmincon---------------------------------')
thetaML = fmincon(@(theta)ARMAXobjectiveML(theta,p2_y,sigma,u),...
                   thetaML,[],[],[],[],[],[],@(x)ARMAXconstraint());
disp('---------------------------------------------------------------------')
%% Return value
p2_theta_ML = thetaML;

%% Display the likelihood function and equation for computing p2_theta_ML

% Probability density function
theta_range = [-0.546:0.00001:-0.541]; idx=1;
fML = zeros(length(theta_range),1);
expML = zeros(length(theta_range),1);
denML = sqrt((2*pi)^(N)*det(sigma));
sigma_inv = sigma\eye(length(sigma));
for i=theta_range
    expML(idx) = 1/2*((p2_y-u*[1;i])-nu).'*sigma_inv*((p2_y-u*[1;i])-nu);
    fML(idx) = 1/denML * exp(-expML(idx));
    idx = idx + 1;
end
figure(1);
plot(theta_range,fML,'b','linewidth',1); grid on; hold on;
xlabel('Theta')
ylabel('Probability density function amplitude')

%Estimated optimal theta
expML_opt = 1/2*((p2_y-u*[1;thetaML])-nu).'*sigma_inv*((p2_y-u*[1;thetaML])-nu);
fML_opt = 1/denML * exp(-expML_opt);
plot(thetaML,fML_opt,'ob'); hold on;

%% Documentation
explanation1 = [...
'\n'...
'We know from the problem data that: \n'...
'     > y(k) = u(k) + theta*u(k-1) + v(k),   \n'...
'        with k=0,...,K-1 (where K is the length of input data p1_u)\n'...
'     > v(k) = c1*e(k) + c2*e(k-1), where e(k) are independently and identically \n'...
'       normally distributed with N(0,1)\n'...
'     > parameter theta is modelled as a random variable generated by N(-0.5,0.5)\n'...
'\n'...
'The important thing to notice here is that v(k) depends not only on e(k), \n'...
'but also on e(k-1). The observations are therefore not independent !\n'...
'\n'...
'In order to compute the estimate of theta by using the Maximum Likelihood, \n'...
'I begin by setting theta to an arbitrarily chosen value. Similarly as in\n'...
'exercise 10, I define: \n'...
'\n'...
'    z(k) = y(k) - u(k) - theta*u(k-1) = v(k) = c1*e(k) + c2*e(k-1)\n'...
'\n'...
'And I set Z = [z(1);  z(2); ...; z(K)]. \n'...
'\n'...
'By fixing theta, we can clearly see that Z is drawn from the distribution \n'...
'N(mu, Sigma), where:\n'...
'     > mu = E( z(k) ) = E( c1*e(k) + c2*e(k-1) )\n'...
'     > Sigma = E( (z(k)-mu) * (z(k)-mu)^T )\n'...
'\n'...
'Since e(k) are independently and identically normally distributed with N(0,1), \n'...
'then E(e(k))=E(e(k-1))=0 and we can already conclude that mu=0. Sigma is \n'...
'therefore computed with: E(Z*transpose(Z)). \n'...
'After some mathematical derivations, the covariance matrix Sigma is found \n'...
'to be the NxN matrix given by the following (where N is the length of p2_u):\n'...
'     (c1^2)*lambda         if k=m=1\n'...
'     (c1^2+c2^2)*lambda    if k=m and k>=2\n'...
'     c1*c2*lambda          if k=1, m=2 or if k=2, m=1\n'...
'     c1*c2*lambda          if |k-m|=1 and min{k,m}>=2\n'...
'     0                     if |k-m|>=2\n'...
' \n'...
'Now we can define the probability density function for Z, defined similarly \n'...
'as seen in exercise 10, by the following Gaussian distribution:\n'...
'\n'...
'-------------------------------------------------------------------------------------------\n'...
'                               1\n'...
'fML(Z|theta) =  ------------------------------ * exp[ -1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu)]\n'...
'                (2pi)^(K/2) * det(Sigma)^(1/2)\n'...
'-------------------------------------------------------------------------------------------\n'...
'\n'...
'The maximum likelihood estimator is the value for theta that maximizes this \n'...
'likelihood function (slide 11.4). However, it is often mathematically easier \n'...
'to consider the log-likelihood function: instead of looking for the peak of \n'...
'the likelihood function, we look for the peak of the logarithm of the \n'...
'likelihood function (slide 11.7). As the log function is monotonic, this \n'...
'gives the same result for theta.\n'...
'Furthermore, if we choose the prediction error cost function -ln(fML), \n'...
'then: maximizing fML is equivalent to minimizing -ln(fML). Therefore:\n'...
'theta_ML = argmax( fML(Z|theta) ) \n'...
'         = argmax( ln(fML(Z|theta)) ) \n'...
'         = argmin( -ln(fML(Z|theta)) )\n'...
'         = argmin( -ln(constant) + 1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu) )\n'...
'\n'...
'Where the constant is 1 / ( (2pi)^(K/2) * det(Sigma)^(1/2) ). As this \n'...
'constant is fixed, in order to compute theta we can discard it and simply compute:\n'...
'theta_ML = argmin( 1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu) )\n'...
'\n'...
'This minimization is done with the Matlab function fmincon. Finally, we find that \n'...
'the estimated theta found by performing maximum likelihood is:\n'...
'--------------------------------------------------------------------------\n'...
'|                theta_ML = ',num2str(p2_theta_ML),'\n'...
'--------------------------------------------------------------------------\n'...
'\n'...
'The probability density function as defined earlier is plotted in blue \n'...
'on figure 1,together with the density function of MAP (which we will detail\n'...
'in part 2). The blue round marker shows the optimal theta that was computed\n'...
'using maximum likelihood.\n'...
'\n'...
'Figure 2 shows the real plant output (p2_y), as well as the plant output\n'...
'estimated with p2_theta_ML. The dotted line represents the error between\n'...
'them. We can clearly see that even if the estimation isnt perfect, it tracks\n'...
'the real signal very well.\n'...
];
fprintf(explanation1);


%% --------------------------------------------------------------------- %%
%% PART 2 
%% --------------------------------------------------------------------- %%
disp(' ');
disp('#####################################################################')
disp('#                             PART 2:                               #')
disp('#                  Maximum A Posteriori Estimate                    #')
disp('#####################################################################')
disp(' ');

% rough estimate of theta
thetaMAP = 0;

%% Optimization
u = zeros(N,2);
u(:,1) = p2_u(:);
u(2:end,2) = p2_u(1:end-1);

disp('-----------------------------fmincon---------------------------------')
thetaMAP = fmincon(@(theta)ARMAXobjectiveMAP(theta,p2_y,u,sigma),...
                   thetaMAP,[],[],[],[],[],[],@(x)ARMAXconstraint());
disp('---------------------------------------------------------------------')

%% Return value
p2_theta_MAP = thetaMAP;

%% Display the MAP function and equation for computing p2_theta_MAP

% Probability density function
theta_range = [-0.546:0.00001:-0.541]; idx = 1;
fMAP = zeros(length(theta_range),1);
denML = sqrt((2*pi)^(N)*det(sigma)*(2*pi*0.5));
for i=theta_range
    fMAP(idx) = 1/2*((p2_y-u*[1;i])).'*(sigma\eye(length(sigma)))*...
       ((p2_y-u*[1;i])) + (i+1/2)^2;
    fMAP(idx) = 1/denML*exp(-fMAP(idx));
    idx = idx + 1;
end
figure(1);
plot(theta_range,fMAP,'r','linewidth',1); grid on; hold on;
xlabel('Theta')
ylabel('Amplitude of the distribution')

% Estimated optimal theta
fMAP_opt = 1/2*((p2_y-u*[1;thetaMAP])-nu).'*sigma_inv*((p2_y-u*[1;thetaMAP])-nu) + (thetaMAP+1/2)^2;
fMAP_opt = 1/denML*exp(-fMAP_opt);
plot(thetaMAP,fMAP_opt,'ro')
xlim([-0.546 -0.541])

legend('Maximum Likelihood Probability Density Function',...
       'Estimated theta with ML',...
       'Maximum A Posteriori Probability Density Function',...
       'Estimated theta with MAP','location','southeast')
title('Likelihood functions')


%% Documentation
explanation2 = [...
'\n'...
'The Maximum A Posteriori (MAP) estimate is similar to the ML one, except \n'...
'that we have a priori information to take into account. We are given the \n'...
'following additional information: the parameter theta is modeled as a random\n'...
'variable generated by the distribution N(-0.5,0.5). This information was \n'...
'neglected to compute the ML estimate, but it is crucial for MAP.\n'...
'\n'...
'The preliminary steps can be done similarly as in part 1. We define:\n'...
'     > z(k) = y(k) - u(k) - theta*u(k-1) = v(k) = c1*e(k) + c2*e(k-1)\n'...
'     > Z = [z(1);  z(2); ...; z(K)] and is drawn from N(mu,Sigma)\n'...
'       Where mu and sigma are the same as in part 1.\n'...
' \n'...
'The big difference comes from the definition of the probability density \n'...
'function for Z, as we must now include a the a priori distribution for theta. \n'...
'As mentioned earlier, theta is drawn from N(mu_AP,sigma_AP) = N(-0.5,0.5), \n'...
'where mu_AP is the a priori mean and sigma_AP the a priori variance of theta. \n'...
'The MAP estimate actually maximizes the product of the joint density function\n'...
'for Z given theta with the a priori distribution for theta (slide 11.11). \n'...
'The probability density function for Z is therefore defined as:\n'...
'\n'...
'fMAP(Z|theta) = fML(Z|theta) * fAP(theta)\n'...
'\n'...
'Where fML(Z|theta) is the distribution defined in part 1, and fAP(theta) \n'...
'is the a priori distribution of theta.\n'...
'\n'...
'We can therefore define the probability density function for Z as the \n'...
'following Gaussian distribution (slides 11.13-11.14):\n'...
'\n'...
'-------------------------------------------------------------------------------------------\n'...
'                                        1                     -1\n'...
'fMAP(Z|theta) = fML(Z|theta) *  ------------------- * exp[ ---------- *(theta - mu_AP)^2]\n'...
'                                (2pi*sigma_AP)^(1/2)       2*sigma_AP\n'...
'\n'...
'\n'...
'                               1\n'...
'             =  ------------------------------ *  exp[ -1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu)]\n'...
'                (2pi)^(K/2) * det(Sigma)^(1/2)\n'...
'                             1                     -1\n'...
'                 *  -------------------  exp[  ---------- *(theta - mu_AP)^2]\n'...
'                    (2pi*sigma_AP)^(1/2)       2*sigma_AP\n'...
'-------------------------------------------------------------------------------------------\n'...
'\n'...
'We have to be careful here not to simplify this function as what was done \n'...
'in exercise 10 when computing MAP. Indeed, in the exercise set, v(k) only \n'...
'depends on e(k) and not on e(k-1), which allows some simplifications to be \n'...
'made. \n'...
'However, in our case, v(k) is also dependent on e(k-1) and we therefore \n'...
'cant use the same formula as the exercise set. Instead, we keep the general \n'...
'Gaussian distribution defined above.\n'...
'\n'...
'Similarly as in part 1, finding the theta that maximizes fMAP is equivalent \n'...
'to finding the theta that maximizes ln(fMAP), which is also equivalent \n'...
'to minimizing -ln(fMAP). Therefore, we compute the following:\n'...
'theta_MAP = argmax( fMAP(Z|theta) ) \n'...
'          = argmax( ln(fMAP(Z|theta)) ) \n'...
'          = argmin( -ln(fMAP(Z|theta)) )\n'...
'          = argmin( -ln(constant) + 1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu) \n'...
'                                  + 1/(2*sigma_AP)*(theta-mu_AP)^2 )\n'...
'\n'...
'For the same reasons as discussed in part 1, we can ignore the constant \n'...
'when performing this minimization. Therefore:\n'...
'theta_MAP = argmin[ 1/2 * (Z-mu)^T * Sigma^(-1) * (Z-mu) \n'...
'                    + 1/(2*sigma_AP)*(theta-mu_AP)^2     ]\n'...
'\n'...
'Computing this with fmincon, we finally find that:\n'...
'--------------------------------------------------------------------------\n'...
'|                theta_MAP = ',num2str(p2_theta_MAP),'\n'...
'--------------------------------------------------------------------------\n'...
'\n'...
'The probability density function as defined earlier is plotted in red \n'...
'on figure 1, together with the density function of ML. The red round marker \n'...
'shows the optimal theta that was computed using MAP. The difference in amplitude\n'...
'between the ML and MAP function is due to the additional constant in the MAP\n'...
'function that comes from the a priori distribution of theta.\n'...
'\n'...
'Figure 3 shows the real plant output (p2_y), as well as the plant output\n'...
'estimated with p2_theta_MAP. The dotted line represents the error between\n'...
'them. Similarly as for part 1, we can see that even if the estimate isnt\n'...
'fitting perfectly the output, it is still very close. We can notice that these\n'...
'plots looks exactly the same as the ones on figure 2 (ML). This will be\n'...
'discussed in part 3.\n'...
];
fprintf(explanation2);

%% Extra Plots for ML and MAP
if PLOT2_y
    figure(2);
    y_estML(1,:) = p2_u(1) + c1*v(1);
    for k = 2:N
        y_estML(k,:) = p2_u(k) + thetaML*p2_u(k-1) + c1*v(k) + c2*v(k-1);
    end
    plot([1:1:N],p2_y,'linewidth',1);
    hold on;
    plot([1:1:N], y_estML,'linewidth',1);
    plot([1:1:N],p2_y-y_estML,'--','linewidth',1);
    legend('Real output',...
        'Output estimated with theta_{ML}',...
        'Error','Location','northwest')
    title('Comparison between real output and output estimated with theta_{ML}')
    xlabel('index k')
    ylabel('Amplitude of signal')
    xlim([1 N])
    grid on
end
if PLOT3_y
    figure(3)
    y_estMAP(1,:) = p2_u(1) + c1*v(1);
    for k = 2:N
        y_estMAP(k,:) = p2_u(k) + thetaMAP*p2_u(k-1) + c1*v(k) + c2*v(k-1);
    end
    plot([1:1:N],p2_y,'linewidth',1);
    hold on;
    plot([1:1:N],y_estMAP,'linewidth',1);
    plot([1:1:N],p2_y-y_estMAP,'--','linewidth',1);
    legend('Real output',...
           'Output estimated with theta_{MAP}',...
           'Error','Location','northwest')
    title('Comparison between real output and output estimated with theta_{MAP}')
    xlabel('index k')
    ylabel('Amplitude of signal')
    xlim([1 N])
    grid on
end

%% --------------------------------------------------------------------- %%
%% PART 3
%% --------------------------------------------------------------------- %%
disp(' ');
disp('#####################################################################')
disp('#                             PART 3:                               #')
disp('#                  Comparison between ML and MAP                    #')
disp('#####################################################################')
disp(' ');

difference = abs(p2_theta_MAP-p2_theta_ML);

%% PLOTS
fig = figure;
left_color = [0 0 1];
right_color = [0 1 0];
set(fig,'defaultAxesColorOrder',[left_color; right_color]);

figure(4);

theta_range2 = [-5:0.00001:5];
norm = normpdf(theta_range2,-0.5,0.5);
subplot(1,2,1);
yyaxis left
plot(theta_range,fML,'b','linewidth',1); hold on;
plot(theta_range,fMAP,'r','linewidth',1); grid on;
yyaxis right
plot(theta_range2,norm,'g','linewidth',1); hold on;
ylabel('Amplitude of the distribution')
xlim([-1 0]);
legend('ML Probability Density Function',...
       'MAP Probability Density Function',...
       'Distribution of theta','Location','southeast');
xlabel('Theta')
ylabel('Amplitude of the distribution')
title('Comparison of the distribution of theta with the ML and MAP functions')

theta_range = [-0.546:0.00001:-0.541];
norm = normpdf(theta_range,-0.5,0.5);
subplot(1,2,2);
yyaxis left
plot(theta_range,fML,'b','linewidth',1); hold on;
plot(theta_range,fMAP,'r','linewidth',1); grid on;
yyaxis right
plot(theta_range,norm,'g','linewidth',1); hold on;
ylabel('Amplitude of the distribution')
xlim([-0.546 -0.541]);
legend('ML Probability Density Function',...
       'MAP Probability Density Function',...
       'Distribution of theta','Location','southeast');
xlabel('Theta')
ylabel('Amplitude of the distribution')
title('Zoom on the ML and MAP functions')


%% Documentation
explanation3 = [...
'We can notice that the values obtained for p2_theta_ML and p2_theta_MAP \n'...
'are the same. When computing their difference, we obtain something of order \n'...
'10^(-9), which is extremely small: |p2_theta_MAP-p2_theta_ML| = ',num2str(difference),'.\n'...
'This can also be seen on figure 2 and 3, as the estimated output looks exactly \n'...
'the same both with ML and MAP. \n'...
'\n'...
'The explanation for this can be derived from the following facts: in the \n'...
'case where theta has a uniform distribution, then MAP gives the same as ML \n'...
'(slide 11.11). As there is no indication on why one is more likely than any \n'...
'other, the maximum likelihood is the same. The limits of the distribution \n'...
'are important, but effectively, between those limits, MAP is the same as ML.\n'...
'In our case, it is true that we dont have a uniform distribution for theta, \n'...
'but a normal one: theta is drawn from N(-0.5,0.5). However, when plotting \n'...
'the distribution of theta together with the density functions for ML and \n'...
'MAP, we can see that it is extremely wide in comparison to the ML/MAP \n'...
'functions (figure 4 left). When zooming in (figure 4 right) on the ML/MAP \n'...
'functions, we can see that the normal distribution can be approximated as \n'...
'a linear function with an extremely small slope. Indeed, when looking at \n'...
'the scale, we realize that while ML and MAP go from 0  up to a magnitude \n'...
'of order 10^8, the distribution of theta only increases by a value of \n'...
'order 10^(-4). \n'...
'Therefore, in the window of interest for theta, we can approximate the \n'...
'distribution of theta as a quasi-uniform distribution, which yields the \n'...
'results mentioned above: theta_ML and theta_MAP are almost equal, with a\n'...
'difference of order 10^(-9).\n'...
'\n'...
];
fprintf(explanation3);



end

%% --------------------------------------------------------------------- %%
%% ARMAX related functions
%% --------------------------------------------------------------------- %%
function [costML] = ARMAXobjectiveML(theta,p2_y,sigma,u)   
    costML = 1/2*((p2_y-u*[1;theta])).'*(sigma\eye(length(sigma)))*...
       ((p2_y-u*[1;theta]));
end

function [costMAP] = ARMAXobjectiveMAP(theta,p2_y,u,sigma) 
    costMAP = 1/2*((p2_y-u*[1;theta])).'*(sigma\eye(length(sigma)))*...
       ((p2_y-u*[1;theta])) + 1*(theta+1/2)^2;
end

function [c,ceq] = ARMAXconstraint()
    ceq = [];
    c = [];
end